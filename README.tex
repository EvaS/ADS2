\documentclass[11pt]{article}
\usepackage[margin=2.7cm,nohead]{geometry}
\usepackage{url}
\usepackage{graphicx}

\title{Project 2 \\ Advanced Databases \\}

\author{
Amandeep  Singh\\as3947@columbia.edu
\and
Evangelia  Sitaridi \\ es2996@cs.columbia.edu
}

\date{\today}


\begin{document}
\maketitle

\section{Description}
For classification and content summary construction we used the fixed classification tree of figure \ref{fig:tree}, given in the description of the project. The queries
used for the classification are in directory queries, included in the submission compressed file. Our implementation has two main classes shown in \ref{fig:classes}.

\begin{figure}[htb!]
\centering
\includegraphics[width=90mm]{cattree}
\caption{Category tree}
\label{fig:tree}
\end{figure}


\begin{figure}[htb!]
\centering
\includegraphics[width=35mm]{classes}
\caption{Implementation Classes}
\label{fig:classes}
\end{figure}

\subsection{Classification}
To classify the given database we traverse each level of the category tree and compute the following metrics for each category:

\[ECoverage(D,Ci)=\sum_{\ \ q: \ query \ probe \ for \ C_i}{f(q)} \]

\[ESpecificity(D, C_i ) = \frac{ESpecificity(D, Parent(C_i )) \times ECoverage(D, C_i )} {\sum_{C_j \  is \ a \ child \ of \ Parent(C_i)} {ECoverage(D,C_j)}} \]

pruning the categories that do not meet the specificity and coverage criteria. We implemented an iterative version of QProber \cite{QProb}. The pseudocde is provided below.

\begin{verbatim}
Classify(Ts,Tc)
    Cat={Root}
    insert Root to L
    P=Root
    level=0
    do{
    for each category P in L
        read P query-file  F
        add to L children of P
        for each query q in F
            pose-query(q)
            store top-4 results
            update coverage of P 
            update coverage of q.child
         if(P.specificity>=Ts && P.coverage>=Tc)
            add P to Cat
    }while(levels<=2)
    return Cat
\end{verbatim}

\subsection{Content Summary Construction}
For this step we just parse the top-documents fetched during query-probes from the classification step for each of the classified categories. We eliminate duplicates before constructing 
a content-summary. We also decided not to include multiple-word entries to the content summaries. To space the requests to the web-sites we process first parse the fetched document and then we fetch
the next url. To parse the documents we used a slight variation of the provided Java script.

\subsection{Exception handling}
There are two main types of exceptions:

\begin{itemize}
\item Connections timeouts when querying Yahoo (java.net.SocketTimeoutException)
\item Http error (code 503)
\end{itemize}

In both cases we retry getting the results from Yahoo, up to a maximum number of tries, set to 100 which is more than enough.

\section{Example}
To test the classification results of QProber we used the provided the examples in the project description and several of the examples from a list
of Largest Deep Web Sites \cite{AIP}. The results \ref{Res1} are for $T_s$=0.6 and coverage $T_c$=100  (computed on 20th of March). The specificity
is >0.5 so all web-pages were classified under one category.

\begin{table}
\begin{tabular}{|c|c|c|}
\hline
\textbf{URL} & \textbf{Description} & \textbf{Classification}\\
\hline
java.sun.com & Java@Sun & Root/Computers/Programming \\
\hline
yahoo.com& Yahoo SE& Root\\
\hline
diabetes.org& American Diabetes Asoc.& Root/Health\\
\hline
tomshardware.com & Tom's Hardware &Root/Computers/Hardware\\
\hline
hardwarecentral.com& PC Hardware Reviews & Root/Computers\\
\hline
espn.com & WorldWide Leader in Sports &Root/Sports/Basketball\\
\hline
portal.acm.org & ACM Digital Library &Root/Computer/Programming\\
\hline
hopkins-aids.edu & HIV guide &Root/Health/Diseases \\
\hline
agiweb.org & American Geological Institute & Root/Health \\
\hline
www.cancer.gov & National Cancer Institute& Root/Health/Diseases\\
\hline
www.ncbi.nlm.nih.gov/PubMed & PubMed & Root/Health/Diseases\\
\hline
www.ovid.com/site/index.jsp & Ovid Technologies &Root/Health/Diseases\\
\hline
soccernet.espn.go.com & Football News \& Scores & Root/Sports/Soccer \\
\hline
www.jumbo.com & Free Computer Software & Root/Computers/Programming\\
\hline
www.webmd.com & Medical News \& Information & Root/Health\\
\hline
www.fitnessmagazine.com & Fitness Magazine & Root/Health/Fitness\\
\hline
www.afaa.com & Aerobic \& Fitness Info of America& Root/Health/Fitness\\
\hline
processing.org & Processing Software & Root/Computer/Programming\\
\hline
www.telegraph.co.uk/sport & Telegraph Sport News & Root/Sports/Soccer\\
\hline
nba.com & National Basketball Association & Root/Sports/Basketball\\
\hline
www.sports.org.au & Australian Athletes with Disability & Root/Sports\\
\hline
\end{tabular}
\caption{Classification for ts=0.3 and tc=100}
\label{Res1}
\end{table}

\section* {Appendix}

\subsection* {File Listing}

We list below the files included in out submission zip. The zip contains the following folders:

[src, lib, queries].
The files are:
\begin{itemize}
\item README.pdf
\item src/YahooProber.java
\item src/URLProcessor.java
\item src/Makefile
\item lib/json.jar
\item queries/Root.txt
\item queries/Computers.txt
\item queries/Health.txt
\item queries/Sports.txt
\end{itemize}

\subsection* {Compilation}
\begin{itemize}
\item \textbf{Compile}: make 
\item \textbf{Clean-up}: make clean 
\item\textbf{Execute}: java -cp .:../lib/json.jar  YahooProber $<url>$ $<t_{es}>$ $<t_{ep}>$ $<yahoo-app-id>$
\item \textbf{Yahoo App Id}: 

BEWTNqTV34H1zojJNQ5MZB48A1vR2mJeNAhKRvk5.bLyZd6gYgQmsVVsqZ7vv32aW73O6VNyzTO
\end{itemize}


\begin{thebibliography}{50}
		\bibitem{AIP} \textit{Largest Deep Web Sites}, \url{http://aip.completeplanet.com/aip-engines/help/largest_engines.jsp}
		\bibitem{QProb} \textit{QProber: A system for automatic classification of hidden-web databases}, Panagiotis G. Ipeirotis,  Luis Gravano,  Mehran Sahami, 2003
\end{thebibliography}

\end{document}